{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-05-27T00:52:48.518408Z","iopub.status.busy":"2022-05-27T00:52:48.517919Z","iopub.status.idle":"2022-05-27T00:53:03.767455Z","shell.execute_reply":"2022-05-27T00:53:03.766779Z","shell.execute_reply.started":"2022-05-27T00:52:48.518321Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:39:52.702291Z","iopub.status.busy":"2022-05-26T14:39:52.701743Z","iopub.status.idle":"2022-05-26T14:40:03.590789Z","shell.execute_reply":"2022-05-26T14:40:03.589893Z","shell.execute_reply.started":"2022-05-26T14:39:52.702254Z"},"trusted":true},"outputs":[],"source":["!pip install torchsummary"]},{"cell_type":"markdown","metadata":{},"source":["# 1. 데이터 전처리"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:03.594156Z","iopub.status.busy":"2022-05-26T14:40:03.593813Z","iopub.status.idle":"2022-05-26T14:40:05.585757Z","shell.execute_reply":"2022-05-26T14:40:05.585015Z","shell.execute_reply.started":"2022-05-26T14:40:03.594114Z"},"trusted":true},"outputs":[],"source":["import torch # 파이토치 기본 라이브러리 \n","import torchvision # 이미지 관련 된 파이토치 라이브러리\n","from torchvision import datasets # 토치비전에서 제공하는 데이터셋\n","from torchvision import transforms # 이미지 전처리 기능들을 제공하는 라이브러리\n","from torch.utils.data import DataLoader # 데이터를 모델에 사용할 수 있도록 적재해 주는 라이브러리\n","from torch.utils.data import random_split\n","from torch.utils.data import ConcatDataset\n","import numpy as np \n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from torchsummary import summary"]},{"cell_type":"markdown","metadata":{},"source":["- training 데이터에서 NORMAL 이미지 수가 PNEUMONIA 이미지 수보다 1/4정도 적음 (1341/3875)\n","- training의 NORMAL데이터를 두배로 불려주는 코드\n","- [참조](https://towardsdatascience.com/fastai-bag-of-tricks-experiments-with-a-kaggle-dataset-part-1-135e46da72f2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:05.587263Z","iopub.status.busy":"2022-05-26T14:40:05.586994Z","iopub.status.idle":"2022-05-26T14:40:05.594501Z","shell.execute_reply":"2022-05-26T14:40:05.593887Z","shell.execute_reply.started":"2022-05-26T14:40:05.587228Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","from PIL import Image\n","import pandas as pd\n","import glob\n","\n","\n","class additional_normal(Dataset):\n","    def __init__(self, root, transform):\n","        self.filepaths = glob.glob(root+'/train/NORMAL/*.jpeg')\n","        self.labels = 0\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.filepaths)\n","\n","    def __getitem__(self, index):\n","        # Pytorch dataset에서는 image데이터를 PIL 형태로 읽음\n","        img_path = self.filepaths[index]\n","        img = Image.open(img_path).convert('RGB')\n","        img_transformed = self.transform(img)\n","        label = 0\n","        return img_transformed, label"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:05.59706Z","iopub.status.busy":"2022-05-26T14:40:05.596519Z","iopub.status.idle":"2022-05-26T14:40:08.290356Z","shell.execute_reply":"2022-05-26T14:40:08.289507Z","shell.execute_reply.started":"2022-05-26T14:40:05.59702Z"},"trusted":true},"outputs":[],"source":["data_dir = '/kaggle/input/chest-xray-pneumonia/chest_xray'\n","\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","train_transform =transforms.Compose([transforms.Resize([224, 224]),\n","                               transforms.RandomHorizontalFlip(p=0.4),\n","                               transforms.RandomAdjustSharpness(sharpness_factor=2),\n","                               transforms.RandomAutocontrast(p=1),\n","                               transforms.RandomRotation(degrees=(-30, 30)),\n","                               transforms.RandomCrop(size=(224, 224)),\n","                               transforms.ToTensor(),\n","                               transforms.Normalize((0.5, 0.5, 0.5), (0.5,0.5,0.5))\n","                                ])\n","test_transform = transforms.Compose([transforms.Resize([224, 224]),\n","                                     transforms.ToTensor(),\n","                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5,0.5,0.5))])\n","\n","trainset = datasets.ImageFolder(root= data_dir + \"/train/\", transform=train_transform)\n","additional_trainset_normal = additional_normal(root=data_dir, transform=train_transform)\n","trainset = ConcatDataset([trainset, additional_trainset_normal])\n","validset = datasets.ImageFolder(root= data_dir + \"/val/\", transform=test_transform)\n","testset = datasets.ImageFolder(root= data_dir + \"/test/\", transform=test_transform)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:08.292247Z","iopub.status.busy":"2022-05-26T14:40:08.291957Z","iopub.status.idle":"2022-05-26T14:40:08.301421Z","shell.execute_reply":"2022-05-26T14:40:08.30041Z","shell.execute_reply.started":"2022-05-26T14:40:08.292207Z"},"trusted":true},"outputs":[],"source":["len(trainset)\n","# len(testset)"]},{"cell_type":"markdown","metadata":{},"source":["# 2. 데이터 시각화"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:08.303695Z","iopub.status.busy":"2022-05-26T14:40:08.303252Z","iopub.status.idle":"2022-05-26T14:40:12.547522Z","shell.execute_reply":"2022-05-26T14:40:12.546818Z","shell.execute_reply.started":"2022-05-26T14:40:08.303655Z"},"trusted":true},"outputs":[],"source":["labels_map = {0:'NORMAL', 1:'PNEUMONIA'}\n","\n","fig = plt.figure(figsize=(16, 16))\n","columns = 5\n","rows = 5\n","search_idx = 0\n","for i in range(1,columns*rows +1):\n","    while trainset[search_idx][1] != 0:\n","        search_idx+=1\n","    img = trainset[search_idx][0].permute(1, 2, 0) \n","  # img = img * 0.5 + 0.5 # unnormalize (normalize : (data - 0.5)/0.5))\n","    fig.add_subplot(rows, columns, i)\n","    plt.imshow(img)\n","    # 정답 :trainset[rnd_idx][1] - 정수\n","    plt.title(labels_map[trainset[search_idx][1]])\n","    plt.axis(\"off\")\n","    search_idx+=1\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:12.548792Z","iopub.status.busy":"2022-05-26T14:40:12.548538Z","iopub.status.idle":"2022-05-26T14:40:15.102266Z","shell.execute_reply":"2022-05-26T14:40:15.101674Z","shell.execute_reply.started":"2022-05-26T14:40:12.548758Z"},"trusted":true},"outputs":[],"source":["fig = plt.figure(figsize=(16, 16))\n","\n","search_idx = -1400\n","for i in range(1,columns*rows +1):\n","    while trainset[search_idx][1] != 1:\n","        search_idx-=1\n","    img = trainset[search_idx][0].permute(1, 2, 0) \n","  # img = img * 0.5 + 0.5 # unnormalize (normalize : (data - 0.5)/0.5))\n","    fig.add_subplot(rows, columns, i)\n","    plt.imshow(img)\n","    # 정답 :trainset[rnd_idx][1] - 정수\n","    plt.title(labels_map[trainset[search_idx][1]])\n","    plt.axis(\"off\")\n","    search_idx-=1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:15.104994Z","iopub.status.busy":"2022-05-26T14:40:15.103595Z","iopub.status.idle":"2022-05-26T14:40:15.110257Z","shell.execute_reply":"2022-05-26T14:40:15.109672Z","shell.execute_reply.started":"2022-05-26T14:40:15.104954Z"},"trusted":true},"outputs":[],"source":["print(len(trainset))\n","print(len(validset))\n","print(len(testset))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:15.112026Z","iopub.status.busy":"2022-05-26T14:40:15.111366Z","iopub.status.idle":"2022-05-26T14:40:15.120052Z","shell.execute_reply":"2022-05-26T14:40:15.119287Z","shell.execute_reply.started":"2022-05-26T14:40:15.111986Z"},"trusted":true},"outputs":[],"source":["batch_size = 16 # 중요한 하이퍼 파라미터, 16 이하로 사용하는것이 성능에 좋다고 알려져 있음\n","trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True) # 훈련용\n","validloader = DataLoader(validset, batch_size=batch_size, shuffle=False) # 검증용\n","testloader = DataLoader(testset, batch_size=batch_size, shuffle=False) # 테스트용"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:15.123256Z","iopub.status.busy":"2022-05-26T14:40:15.122372Z","iopub.status.idle":"2022-05-26T14:40:15.128675Z","shell.execute_reply":"2022-05-26T14:40:15.127809Z","shell.execute_reply.started":"2022-05-26T14:40:15.12322Z"},"trusted":true},"outputs":[],"source":["from torch import nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","import torchvision.models as models"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:15.130793Z","iopub.status.busy":"2022-05-26T14:40:15.129881Z","iopub.status.idle":"2022-05-26T14:40:43.897003Z","shell.execute_reply":"2022-05-26T14:40:43.896091Z","shell.execute_reply.started":"2022-05-26T14:40:15.130757Z"},"trusted":true},"outputs":[],"source":["model = models.vgg16(pretrained=True)\n","model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:45.691483Z","iopub.status.busy":"2022-05-26T14:40:45.691222Z","iopub.status.idle":"2022-05-26T14:40:45.720224Z","shell.execute_reply":"2022-05-26T14:40:45.719553Z","shell.execute_reply.started":"2022-05-26T14:40:45.691455Z"},"trusted":true},"outputs":[],"source":["for param in model.parameters():\n","    param.requires_grad = False\n","    \n","# model.fc = nn.Linear(in_features=512, out_features=2, bias=True)\n","\n","model.classifier[3] = nn.Linear(in_features=4096, out_features=512, bias=True)\n","model.classifier[6] = nn.Linear(in_features=512, out_features=2, bias=True)\n","\n","for param in model.classifier.parameters():\n","    param.requires_grad = True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:47.724048Z","iopub.status.busy":"2022-05-26T14:40:47.723692Z","iopub.status.idle":"2022-05-26T14:40:50.980613Z","shell.execute_reply":"2022-05-26T14:40:50.978913Z","shell.execute_reply.started":"2022-05-26T14:40:47.724006Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:50.991875Z","iopub.status.busy":"2022-05-26T14:40:50.988634Z","iopub.status.idle":"2022-05-26T14:40:57.479034Z","shell.execute_reply":"2022-05-26T14:40:57.47829Z","shell.execute_reply.started":"2022-05-26T14:40:50.991805Z"},"trusted":true},"outputs":[],"source":["from torchsummary import summary\n","summary(model, (3, 244, 244))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:40:57.480899Z","iopub.status.busy":"2022-05-26T14:40:57.480562Z","iopub.status.idle":"2022-05-26T14:41:02.313588Z","shell.execute_reply":"2022-05-26T14:41:02.312837Z","shell.execute_reply.started":"2022-05-26T14:40:57.480861Z"},"trusted":true},"outputs":[],"source":["# !pip install torchmetrics\n","from torchmetrics import F1\n","from torch.utils.tensorboard import SummaryWriter\n","# writer = SummaryWriter()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:41:02.315096Z","iopub.status.busy":"2022-05-26T14:41:02.314825Z","iopub.status.idle":"2022-05-26T14:41:05.24589Z","shell.execute_reply":"2022-05-26T14:41:05.244949Z","shell.execute_reply.started":"2022-05-26T14:41:02.315061Z"},"trusted":true},"outputs":[],"source":["learning_rate = 0.0001\n","criterion = nn.CrossEntropyLoss() # 손실함수\n","f1 = F1(num_classes=2).to(device)\n","# criterion = F1(num_classes=3)\n","# optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9) # 옵티마이저 : Momentum\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.001, betas=[0.9,0.999]) # 규제의 강도 : weight_decay=0.001\n","# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\", patience=7, factor=0.1, verbose=True)\n","# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:41:05.24861Z","iopub.status.busy":"2022-05-26T14:41:05.24832Z","iopub.status.idle":"2022-05-26T14:41:05.255878Z","shell.execute_reply":"2022-05-26T14:41:05.255022Z","shell.execute_reply.started":"2022-05-26T14:41:05.24857Z"},"trusted":true},"outputs":[],"source":["def validation(model, testloader, criterion):\n","    f1_score = 0\n","    test_loss = 0\n","\n","    with torch.no_grad(): # 예측에는 gradient가 필요 없음\n","        for images, labels in testloader: # 1 iteration마다 배치 단위로 image와 label을 가져옴\n","            images, labels = images.to(device), labels.to(device) # data를 GPU로 보내기\n","            # Not Flatten!!!\n","            #images.resize_(images.shape[0], 784) # batch size x 784\n","            \n","            logits = model.forward(images) # 입력 : batch_size, 28, 28\n","            \n","            loss = criterion(logits, labels)\n","            test_loss += loss.item()\n","\n","            probs = F.softmax(logits, dim=1)\n","            _, preds = torch.max(probs, 1) # preds = probs.max(dim=1)[1]\n","            f1_score += f1(labels, preds).item()\n","\n","    return test_loss, f1_score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:41:05.257716Z","iopub.status.busy":"2022-05-26T14:41:05.25747Z","iopub.status.idle":"2022-05-26T14:41:05.274299Z","shell.execute_reply":"2022-05-26T14:41:05.273605Z","shell.execute_reply.started":"2022-05-26T14:41:05.257682Z"},"trusted":true},"outputs":[],"source":["def train(model, epochs, criterion, optimizer):\n","    steps = 0\n","    # 1 에폭(epoch)당 반복수\n","    #iter_per_epoch = len(trainset) / batch_size  \n","    iter_per_epoch = len(trainloader) \n","    print_every = iter_per_epoch\n","    best_f1 = 0\n","    train_loss_list = []\n","    val_loss_list = []\n","    f1_score_list = []\n","    e = []\n","\n","    # for Early stopping ## 모델에서 더이상의 성능 개선 여지가 없을 때 학습을 종료시키는 콜백함수(어떤 함수를 수행시 그 함수에서 내가 지정한 함수를 호출)\n","    min_loss = 1000\n","    trigger = 0\n","    patience = 10 # monitoring 하는 test loss가 더이상 줄지 않는 횟수를 몇번이나 참을지..\n","\n","    for epoch in range(epochs):\n","      model.train()\n","      train_loss = 0\n","      for images, labels in tqdm(trainloader): #iterator에서 batch_size씩 가져와 images와 labels에 전달\n","        steps += 1\n","        images, labels = images.to(device), labels.to(device) # data를 GPU로 보내기\n","        # not Flatten!!\n","        # images.resize_(images.size()[0], 784)\n","        \n","        optimizer.zero_grad() ## zero_grad()는 파라미터들을 업데이트할 때 사용. 루프가 한번 돌고나서 역전파를 하기전에 반드시 zero_grad() 값들을 0으로 초기화시킨 후 학습 진행함\n","\n","        # 1. Forward (Loss 얻게됨)\n","        output = model.forward(images)\n","        loss = criterion(output, labels)\n","\n","        # 2. Backward (Gradient가 오차역전파로 구해짐) ## Backward함수는 어떤 스칼라 값에 대한 출력텐서의 변화도(gradient)를 전달받고, 동일한 스칼라 값에 대한 입력 텐서의 변화도를 계산. 모델의 매개변수들에 대한 손실의 변화도 계산\n","        loss.backward()\n","\n","        # 3. Gradient Descent (Model parameter update) :  W <- W-lr*Gradient ## optimizer.step() 함수는 매개변수를 갱신함\n","        optimizer.step() \n","\n","        train_loss += loss.item() # 1 epoch 당 누적된 로스\n","      \n","        if steps % print_every == 0 : \n","            model.eval() # 배치 정규화, 드롭아웃 이 적용될 경우 model.forward 연산이 training 때와 다르므로 반드시 설정\n","            valid_loss, f1_score = validation(model, validloader, criterion)\n","\n","#             writer.add_scalar(\"Loss/train\", train_loss/len(trainloader), epoch)\n","#             writer.add_scalar(\"Loss/test\", valid_loss/len(validloader), epoch)\n","#             writer.add_scalar(\"F1 Score\",f1_score/len(validloader), epoch)\n","            \n","\n","            print(\"Epoch : {}/{}...\".format(epoch+1, epochs),\n","                  \" Train Loss : {:.3f}\".format(train_loss/len(trainloader) ),\n","                  \" Valid Loss : {:.3f}\".format(valid_loss/len(validloader)),\n","                  \" F1 Score : {:.3f}\".format(f1_score/len(validloader)))\n","        \n","            train_loss_list.append(train_loss/len(trainloader))\n","            val_loss_list.append(valid_loss/len(validloader))\n","            f1_score_list.append(f1_score/len(validloader))\n","            e.append(epoch)\n","\n","            \n","            # Best model 저장\n","            if f1_score > best_f1:\n","                torch.save(model.state_dict(), \"best_checkpoint.pth\")\n","                best_f1 = f1_score\n","\n","            # Early stopping Start ## valid_loss가 min_loss 보다 커지게 되거나, trigger가 patience 보다 커지케 되는 순간 Early stopping() 콜백함수가 학습과정에서 매번 호출함\n","            if valid_loss > min_loss: \n","                trigger +=1\n","                print(\"trigger :\", trigger)\n","                if trigger >= patience: \n","                    print(\"Early Stopping!!!\")\n","                    print(\"Train step is finished!!\")  \n","#                     writer.flush() \n","                    return\n","            else: \n","                min_loss = valid_loss\n","                trigger = 0\n","                # print(\"min loss set to current valid loss!!!\")\n","            # Early stopping End\n","\n","            train_loss = 0\n","            model.train()\n","\n","            # Learning Rate Scheduler \n","            scheduler.step(valid_loss)\n","    return train_loss_list, val_loss_list, f1_score_list, e\n","\n","#     writer.flush()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T14:41:05.275969Z","iopub.status.busy":"2022-05-26T14:41:05.275707Z","iopub.status.idle":"2022-05-26T15:11:24.628245Z","shell.execute_reply":"2022-05-26T15:11:24.627536Z","shell.execute_reply.started":"2022-05-26T14:41:05.275937Z"},"trusted":true},"outputs":[],"source":["train_loss_ls, valid_loss_ls, f1_score_ls, e = train(model, 10, criterion, optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T15:12:44.716775Z","iopub.status.busy":"2022-05-26T15:12:44.716524Z","iopub.status.idle":"2022-05-26T15:12:44.91027Z","shell.execute_reply":"2022-05-26T15:12:44.909616Z","shell.execute_reply.started":"2022-05-26T15:12:44.716748Z"},"trusted":true},"outputs":[],"source":["plt.title(\"Train-Val Loss\")\n","plt.plot(e,train_loss_ls,label=\"train\")\n","plt.plot(e,valid_loss_ls,label=\"val\")\n","plt.ylabel(\"Loss\")\n","plt.xlabel(\"Training Epochs\")\n","plt.legend()\n","plt.show()\n","\n","# # plot accuracy progress\n","# plt.title(\"Train-Val Accuracy\")\n","# plt.plot(range(1,num_epochs+1),metric_hist[\"train\"],label=\"train\")\n","# plt.plot(range(1,num_epochs+1),metric_hist[\"val\"],label=\"val\")\n","# plt.ylabel(\"Accuracy\")\n","# plt.xlabel(\"Training Epochs\")\n","# plt.legend()\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T15:13:33.245907Z","iopub.status.busy":"2022-05-26T15:13:33.245601Z","iopub.status.idle":"2022-05-26T15:13:33.25426Z","shell.execute_reply":"2022-05-26T15:13:33.253534Z","shell.execute_reply.started":"2022-05-26T15:13:33.245874Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, testloader):\n","    f1_accuracy = 0 \n","    test_loss = 0\n","    model.eval()\n","    with torch.no_grad(): # 예측에는 gradient가 필요 없음\n","        for images, labels in testloader: # 1 iteration마다 배치 단위로 image와 label을 가져옴\n","            images, labels = images.to(device), labels.to(device) ##gpu로 image와 label 보내기\n","            # not Flatten!\n","            #images.resize_(images.shape[0], 784) # batch size x 784\n","            logits = model.forward(images) # 입력 : batch * height * width  ## forward()는 모델이 학습데이터(image)를 입력받아서 forward propagation을 진행시키는 함수\n","            \n","            loss = criterion(logits, labels)\n","            test_loss += loss.item()\n","\n","            probs = F.softmax(logits, dim=1) ## softmax(x)는 비선형성이지만, 일반적으 네트워크에서 마지막으로 수행되는 작업이며, 실수의 벡터를 취하여 확률 분포를 반환함. x는 실수 벡터(음수, 양수, 등). 모든 구성요소 합은 1 \n","            _, preds = torch.max(probs, 1) # preds = probs.max(dim=1)[1] ## torch.max()는 텐서에서 최대값을 구하는 함수\n","            correct = (preds == labels).sum()\n","            print(labels, preds)\n","            f1_score = f1(labels, preds)\n","            #accuracy = correct / images.shape[0]\n","            f1_accuracy += f1_score.item() ## pytorch에서 tensor에 저장된 값만 가져오는 방법 \n","\n","    print(\"Test Loss : \", test_loss/len(testloader))\n","    print(\"Average F1 : \", f1_accuracy/len(testloader))\n","\n","    ## 정밀도(Precision), 정확도(Accuracy), 재현율(Recall)\n","    ## Accuracy = TP + TN / TP + FP + TN + FN -> 참을 참으로 거짓을 거짓으로 잘 분류한 비율\n","    ## Precision = TP / TP + FP -> 분류기가 참으로 분류한 결과 중에서 실제 참의 비율(얼마나 정밀하게 참으로 분류했는지) \n","    ## Recall = TP / TP + FN -> 실제 참 중에서 분류기가 참으로 분류한 비율\n","\n","    ## F1 Score는 Precision과 Recall의 조화평균으로 주로 분류 클래스간 데이터가 심각한 불균형을 이루는 경우에 사용\n","    ## F = (b2 + 1) * Precision * Recall / b2 * Precision + Recall \n","\n","    \n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-26T15:13:33.35973Z","iopub.status.busy":"2022-05-26T15:13:33.359441Z","iopub.status.idle":"2022-05-26T15:13:49.247887Z","shell.execute_reply":"2022-05-26T15:13:49.246622Z","shell.execute_reply.started":"2022-05-26T15:13:33.359701Z"},"trusted":true},"outputs":[],"source":["evaluate(model, testloader)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
